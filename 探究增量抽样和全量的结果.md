<center><font size=7>**比较全量、抽样与增量三种方式**</font></center>

## 1. 增量学习的概念
&nbsp; &nbsp; &nbsp; &nbsp;增量学习(Incremental Learning)是指一个学习系统能不断地从新样本中学习新的知识，并能保存大部分以前已经学习到的知识。增量学习非常类似于人类自身的学习模式。其应用的场景主要是：

- 数据库非常大的情况，无法一次性装入计算机内存
- 流数据，随时间的变化不断变化
 
增量学习的主要特点如下：

- 可以从新数据中学习新知识。当新增数据时，只做关于新增数据引起的更新，同时保存以前学习到的大部分知识。
- 以前已经处理过的数据不需要重复处理
- 学习系统没有关于整个训练样本的先验知识
- —旦学习完成后训练观测样本被丢弃


## 2. 全量与增量的差异
&nbsp; &nbsp; &nbsp; &nbsp;增量训练与全量训练相比的差别，用一个例子来说明。假设有200条数据，用增量训练的方法，第一次训练150条，第二次训练50条。这个和全量训练直接拿200条数据得到的结果相比：**在第二次训练50条数据的时候，前150条数据已经不存在了，因此模型更拟合于后面的新数据。**

&nbsp; &nbsp; &nbsp; &nbsp;同样的，假如最后的一批数据质量比较差，那也可能会影响到之前的训练结果，把模型带偏。

&nbsp; &nbsp; &nbsp; &nbsp;Xgboost提供的增量训练方法，是从一个现有的树出发，只更新现有的树结构，基于新一批的数据，更新原有树节点的统计量和叶子节点的值。
如果要用增量训练，最好是保证增量数据的质量均匀分布，防止带偏模型。

## 3. 实验
&nbsp; &nbsp; &nbsp; &nbsp;原始的总数据集很大有接近1800万行，而这里的实验用之前抽样的数据作为假想中的“全量数据”，即：总样本量为89万行，用户个数为5436个。（把这个数据集看成全量的，然后分析抽样结果与增量训练的结果对比）
实验中的抽样数据，则是随机抽取了这个假想的“全量数据集”的用户，取5%的用户，这些用户的行为数据构成了抽样训练集，大约有5万行。
模型的参数较之前没有调整，每轮迭代读入5万行数据进行incremental training，具体设置的参数是：

- `process_type = update`: 从已有的模型出发，保留树的结构不变，
- `updater = refresh`：指定每轮迭代时树的更新方式。`refresh`表示利用新的数据，刷新原有树的内部节点的统计量。这里不会进行随机行采样。
- `refresh_leaf = True`：关于`updater=refresh`的一个参数，设置为`True`时，不仅更新树的内部节点统计量，还会刷新叶子节点的输出值。

### 3.1 按默认数据集顺序读入
&nbsp; &nbsp; &nbsp; &nbsp;默认的训练集是按照动漫的id排序的，即不同用户不同时间更新的关于同一部动漫的评分以及观看状态，在训练集中是处在连续的一个片段中。结果如下：

<table>
   <caption>Table 3.1: Incremental training with default data order</caption>
   <tr>
      <td>召回组合</td>
      <td>召回率</td>
      <td>精准率</td>
      <td>命中率</td>
      <td>覆盖率(占比)</td>
      <td>覆盖率(信息熵)</td>
      <td>覆盖率(type的信息熵)</td>
   </tr>
   <tr>
      <td>90w“全量”数据</td>
      <td>7.469%</td>
      <td>11.203%</td>
      <td>77.872%</td>
      <td>21.296%</td>
      <td>8.067632605</td>
      <td>1.333672452</td>
   </tr>
   <tr>
      <td>5%用户抽样(5.1w)</td>
      <td>6.242%</td>
      <td>8.889%</td>
      <td>78.571%</td>
      <td>9.148%</td>
      <td>8.148716012</td>
      <td>1.390282018</td>
   </tr>
   <tr>
      <td>增量训练(5w)首轮</td>
      <td>6.819%</td>
      <td>10.228%</td>
      <td>75.574%</td>
      <td>22.256%</td>
      <td>8.151649871</td>
      <td>1.351169404</td>
   </tr>
   <tr>
      <td>增量训练(5w)末轮</td>
      <td>7.127%</td>
      <td>10.690%</td>
      <td>76.824%</td>
      <td>18.056%</td>
      <td>7.936399226</td>
      <td>1.303683283</td>
   </tr>
   <tr>
      <td></td>
   </tr>
</table>

&nbsp; &nbsp; &nbsp; &nbsp;从上表可以看出：从首轮到末轮，模型的预测效果有了较为明显的提高，更接近于全量数据下的表现，同时显著优于抽样数据下的表现。

### 3.2 按时间顺序读入
&nbsp; &nbsp; &nbsp; &nbsp;上面的默认数据集顺序导致了每次读取的part of data只包含小部分动漫的信息。这一次把全量数据集按照用户更新状态打分的时间排序，然后按时间顺序由远及近读入。结果如下：

<table>
   <caption>Table 3.2: Incremental training with update date order</caption>
   <tr>
      <td>召回组合</td>
      <td>召回率</td>
      <td>精准率</td>
      <td>命中率</td>
      <td>覆盖率(占比)</td>
      <td>覆盖率(信息熵)</td>
      <td>覆盖率(type的信息熵)</td>
   </tr>
   <tr>
      <td>90w“全量”数据</td>
      <td>7.469%</td>
      <td>11.203%</td>
      <td>77.872%</td>
      <td>21.296%</td>
      <td>8.067632605</td>
      <td>1.333672452</td>
   </tr>
   <tr>
      <td>5%用户抽样(5.1w)</td>
      <td>6.651%</td>
      <td>9.471%</td>
      <td>79.365%</td>
      <td>7.469%</td>
      <td>7.825825802</td>
      <td>1.321671186</td>
   </tr>
   <tr>
      <td>增量训练(5w)首轮</td>
      <td>7.203%</td>
      <td>10.804%</td>
      <td>76.179%</td>
      <td>22.166%</td>
      <td>8.226319</td>
      <td>1.330604</td>
   </tr>
   <tr>
      <td>增量训练(5w)末轮</td>
      <td>7.271%</td>
      <td>10.906%</td>
      <td>77.630%</td>
      <td>17.622%</td>
      <td>7.812633</td>
      <td>1.300618</td>
   </tr>
   <tr>
      <td></td>
   </tr>
</table>

&nbsp; &nbsp; &nbsp; &nbsp;从上表可以看出：从首轮到末轮，模型的预测效果基本没有什么变化，从首轮开始其实就比较接近于全量数据下的表现了，每轮的更新迭代也只是在上下震荡。效果仍然显著优于抽样的结果

### 3.3 按随机顺序读入
&nbsp; &nbsp; &nbsp; &nbsp;最后，试着把全量数据集随机shuffle打乱，然后依次读入，没有任何顺序。效果如下：

<table>
   <caption>Table 3.3: Incremental training with random order</caption>
   <tr>
      <td>召回组合</td>
      <td>召回率</td>
      <td>精准率</td>
      <td>命中率</td>
      <td>覆盖率(占比)</td>
      <td>覆盖率(信息熵)</td>
      <td>覆盖率(type的信息熵)</td>
   </tr>
   <tr>
      <td>90w“全量”数据</td>
      <td>7.469%</td>
      <td>11.203%</td>
      <td>77.872%</td>
      <td>21.296%</td>
      <td>8.067632605</td>
      <td>1.333672452</td>
   </tr>
   <tr>
      <td>5%用户抽样(5.1w)</td>
      <td>6.651%</td>
      <td>9.471%</td>
      <td>79.365%</td>
      <td>7.469%</td>
      <td>7.825825802</td>
      <td>1.321671186</td>
   </tr>
   <tr>
      <td>增量训练(5w)首轮</td>
      <td>7.106%</td>
      <td>10.658%</td>
      <td>76.542%</td>
      <td>22.091%</td>
      <td>8.07655</td>
      <td>1.372281</td>
   </tr>
   <tr>
      <td>增量训练(5w)末轮</td>
      <td>7.323%</td>
      <td>10.984%</td>
      <td>77.227%</td>
      <td>17.697%</td>
      <td>7.831545</td>
      <td>1.315776</td>
   </tr>
   <tr>
      <td></td>
   </tr>
</table>

&nbsp; &nbsp; &nbsp; &nbsp;从上表可以看出：从首轮到末轮，模型的预测效果有些微提升，从首轮开始比较接近于全量数据下的表现了，后续的更新在此基础上略有提升。同样的，也是显著优于抽样结果。

### 3.4 总结
&nbsp; &nbsp; &nbsp; &nbsp;从上面三个实验可以看出，xgboost的增量训练还是起到了一定的效果的，基本上其模型效果都优于单纯的对用户采样的结果，然后略低于全量数据的结果。根据不同的数据读入顺序，增量训练的结果也会有所改变。

## 4. 随机抽样
&nbsp; &nbsp; &nbsp; &nbsp;上面三个实验中，抽样数据的结果和增量的结果比起来差了挺多的，下面对全量训练集（90w）的用户，重复多抽几次样（固定每次5%，更换随机数种子），看看总体的表现：

<table>
   <caption>Table 3.4: Random sampling for users</caption>
   <tr>
      <td>5%用户采样seed</td>
      <td>召回率</td>
      <td>精准率</td>
      <td>命中率</td>
      <td>覆盖率(占比)</td>
      <td>覆盖率(信息熵)</td>
      <td>覆盖率(type的信息熵)</td>
   </tr>
   <tr>
      <td>1001</td>
      <td>6.242%</td>
      <td>8.889%</td>
      <td>78.571%</td>
      <td>9.148%</td>
      <td>8.148716</td>
      <td>1.390282</td>
   </tr>
   <tr>
      <td>1002</td>
      <td>6.603%</td>
      <td>11.093%</td>
      <td>77.600%</td>
      <td>10.063%</td>
      <td>8.253565</td>
      <td>1.476714</td>
   </tr>
   <tr>
      <td>1003</td>
      <td>6.985%</td>
      <td>10.876%</td>
      <td>83.898%</td>
      <td>9.223%</td>
      <td>8.237271</td>
      <td>1.374655</td>
   </tr>
   <tr>
      <td>1004</td>
      <td>7.422%</td>
      <td>10.509%</td>
      <td>75.424%</td>
      <td>9.553%</td>
      <td>8.205792</td>
      <td>1.439307</td>
   </tr>
   <tr>
      <td>1005</td>
      <td>6.274%</td>
      <td>9.546%</td>
      <td>68.182%</td>
      <td>9.373%</td>
      <td>8.101647</td>
      <td>1.342534</td>
   </tr>
   <tr>
      <td>Average</td>
      <td>6.705%</td>
      <td>10.182%</td>
      <td>76.735%</td>
      <td>9.472%</td>
      <td>8.1893982</td>
      <td>1.4046984</td>
   </tr>
   <tr>
      <td></td>
   </tr>
</table>


&nbsp; &nbsp; &nbsp; &nbsp;上表可以看出，随机抽样的结果彼此之间也有着一定的差异，不过平均来说其效果还是低于增量训练以及全量结果的。而上次对“真实全量数据”用增量训练预测的方法得到的结果，对比随机抽样得到的结果（90w数据，5400用户)，二者非常接近。这是不是可以说明，**因为样本量的关系，90w的样本量得到的结果已经很不错了。（作为对比，如果全量是90w的话，抽样得到的5w数据的结果就显得比较单薄）**

P.S. 
1. 其实增量训练主要是针对流数据来使用的，如果单纯的是因为样本量很大的话，一般的实际解决方法是采用分布式的计算平台比如spark之类。只是增量训练也可以一定程度上解决单机跑样本量大的问题。
2. xgboost的增量训练方法，官方文档也只有一点点说明，没有查到相关的具体实现方法..



关于SGD增量学习的网站：
[How does SGD Incremental Learning behave in scikit-learn?](https://stackoverflow.com/questions/57862008/how-does-sgd-incremental-learning-behave-in-scikit-learn)


