<center><font size=7>**推荐系统与机器学习**</font>></center>




协同过滤CF可以分为两类：基于邻域和基于隐语义的


[TOC]
## 1. 推荐系统架构
### 1.1 数据的采集
&nbsp; &nbsp; &nbsp; &nbsp;推荐算法依赖于用户行为数据以及物品数据。以电商数据为例，用户行为可以从下面两个角度分类：

- 产生行为的用户类型：只有注册用户可以发生的行为/所有用户都可以
- 行为的规模：大量（如浏览网页，搜索记录）；中等（如购买，收藏）；少量（如分享，评论，打分）

&nbsp; &nbsp; &nbsp; &nbsp;数据的采集是推荐系统环节中最基础也是最初始的一个步骤。通常，要求**User行为尽可能多的覆盖所有的业务流程，而Item数据尽可能多的覆盖物品的属性维度。**

### 1.2 推荐系统的本质
&nbsp; &nbsp; &nbsp; &nbsp;从本质上说，推荐就是在做用户行为模式挖掘，**找出用户的行为特征，给出相应的预测，其本质是联系用户与物品的媒介**。推荐系统的核心任务可以抽象成下面两个部分：

1. 在一个用户到来时，如何给这个用户生成特征；
2. 如何根据已生成的特征，来找到对应的物品用于推荐。这一步通常是利用特征-物品相关矩阵来完成。

### 1.3 用户特征的生成
&nbsp; &nbsp; &nbsp; &nbsp;常用的用户特征可以分成下面几类：

- 人口统计学特征：比如年龄、性别、国籍等
- 用户行为特征：比如浏览过什么、买过什么、收藏过什么、给什么打过分等等；还可以分为近期行为和长期行为。
- topic model：比如用户曾看过电影1,2,3，这些电影可以生成一个主题叫“武侠电影”，那么说明用户对武侠电影感兴趣。

### 1.4 不同的推荐任务
&nbsp; &nbsp; &nbsp; &nbsp;推荐的任务可以分为很多种(个人理解是推荐物品的过滤，在得到推荐物品list后，根据不同的任务进行过滤？)

- 把新品推荐给用户
- 把商家想要宣传的物品推荐给用户
- 混合推荐：比如把图书和音像制品放在一个list里展示给用户看
- 根据不同场景，推荐不同的新颖度：比如首页推荐热门，而推荐系统页面则推荐长尾
- 上下文推荐，比如一个链接说你可以在听到"李宗盛"，则点击了链接后电台推荐的内容就需要考虑"李宗盛"这个上下文。

### 1.5 推荐系统的组成
&nbsp; &nbsp; &nbsp; &nbsp;前面提到的，由用户行为数据可以生成很多种用户特征，而推荐任务也有很多种类。可以把推荐系统拆分成下面的形式：一个推荐系统 = 多个推荐引擎 + 多个任务。**其中，一个推荐引擎通常负责一类特征，以及一种任务。换句话说，一个推荐引擎代表了一种具体的推荐策略。**（比如根据年龄性别推荐、根据兴趣爱好推荐等）而整个推荐系统的职责，就是把复数个推荐引擎的结果，**根据一定的权重或优先级合并、排序、返回。**

## 2. 推荐引擎的架构
&nbsp; &nbsp; &nbsp; &nbsp;一个推荐引擎主要可以分成下面四个模块：

1. 生成用户特征向量模块： 从数据库中提取用户行为数据，并经过清洗、转化等，生成用户的特征向量。
2. 特征-物品相关推荐模块： 根据用户特征向量，利用feature-item相关矩阵，转化成初始推荐物品列表。可以配置多个相关表，
并赋予不同的权重，最后用一个加权的feature-item相关表来进行推荐。除了返回推荐初始推荐物品列表以外，还需要给列表里的
每一个物品，产生一个解释列表，表明这个推荐结果是因为哪一些feature推荐来的。
3. 过滤模块： 对初始推荐物品列表进行过滤，例如：用户已产生过行为的旧物品、候选物品以外的物品、质量差的物品等。
4. 排序模块： 通常也可以包含多个子模块，如新颖性排名、多样性排名等。主要是为了提升用户体验。


## 3. 基于机器学习的推荐系统
&nbsp; &nbsp; &nbsp; &nbsp;总的来说，基于机器学习的推荐系统可以分解成下面三个步骤：**召回-排序-策略干扰。**

### 3.1 召回
&nbsp; &nbsp; &nbsp; &nbsp;因为完全依赖模型进行推荐的成本太高，所以**需要设计一定的召回策略**，从海量数据中筛选出用户可能感兴趣的，用于推荐的候选物品集。召回的方式有很多种，比如：

- 排序召回：选出最新的N个产品、最热的N个产品、用户最新光顾的N个产品、各种经验上的评分公式等作为候选集；
- 简单召回：**和用户历史行为内容相似的内容。**可以通过用户画像进行匹配，例如：24岁的人喜欢什么；学统计的人喜欢什么；研究生男性喜欢什么等等;
- 规则召回：如朋友的购买、天气等

### 3.2 排序
&nbsp; &nbsp; &nbsp; &nbsp;排序环节就是我们的机器学习算法模型施展拳脚的地方。结合我们根据用户历史行为数据所生成的用户特征（用户画像），还有产品环境信息、推荐内容的特征（单品画像）等，使用机器学习算法，对召回候选集里的物品进行打分排序。
&nbsp; &nbsp; &nbsp; &nbsp;这里的模型可以是回归模型（预测用户点击推荐的内容的概率是多少），也可以是分类模型（预测用户是否会点击）。而模型的训练集（{(X,y)}）就是已收集到的推荐历史数据（比如用户1有没有点击物品1，2等等）

### 3.3 策略干扰
&nbsp; &nbsp; &nbsp; &nbsp;推荐除了要考虑准确的召回，同时也要兼顾用户体验。比如多样性等。而单纯靠算法，很多东西是无法控制的。因此在算法对召回物品进行排序打分后，还需要对结果进行一定的人工干预，才能最后展示在用户面前。下面是常见的干预策略：

- 过滤掉用户已经产生过行为的物品。**推荐系统的目的是帮助用户发现新的物品，这和kfc tradeup推荐不一样！！**
- 过滤掉某些质量很差的物品
- 强行插入重度投入的头部内容，无论从产品或是运营的角度都有实际需求。
- 保证结果的多样性。比如可以将推荐结果按照某种物品属性分成几类，然后在每类中取top1组合后返回（如推荐电影，可以推荐爱情片、科幻片、动作片）

### 3.4 对比
&nbsp; &nbsp; &nbsp; &nbsp;把基于机器学习的推荐系统，和上面《推荐系统实践》书中介绍的推荐引擎四大模块作个比较：
在四大模块中，A和B一起起到的是召回+排序的功能。


GBDT用的最多的地方就是推荐系统最后的精排阶段
比如，参考网址https://www.cnblogs.com/freedommovie/p/7783750.html里提到的：
“根据商品、素材拉取用户特征、品类特征、素材特征、用户素材交互特征、上下文特征、用户手机信息、地理位置等多个维度30
几个特征，传入训练出来GBDT模型，进行线上点击量预估，估计用户对于素材点击量几率，根据几率排序商品。

--------------------------------------------------------------------------------------

## 4. 用MyAnimeList数据集做推荐
### 4.1 关于评分预测和Top-N推荐（非常重要！！）
&nbsp; &nbsp; &nbsp; &nbsp;首先要知道这两个东西不是同一个。评分预测好的模型不一定适合用来做top-N，因为评分预测的损失小可能是对bad item的预测效果好，而对good item的预测很差，甚至不如一个损失较大，但是对good item预测好，对bad item预测效果相当差的模型，所以评分预测和top-N应该分开看成两个问题。比方说：一个用户给动画A,B,C,D打分分别为10,8,4,3。评分模型可能预测的得分是7,5,4,3，topN可能是8,6,2,1，前者的均方差小，但是只是因为把4分和3分的动画预测的比较准，这没啥用因为它把用户实际上喜欢的动画AB给预测的得分比较低。。**这个例子说明，在很多情况下，RMSE下降了，但是topN排序并没有变好，甚至变差，**

&nbsp; &nbsp; &nbsp; &nbsp;对于top-N推荐，现有大多数方法的原理是转换成评分预测问题，根据已有的历史数据来预测用户对新内容的评分。这些历史信息可以是显式的如评分、评论文本，也可以是隐式的如购买历史、浏览历史等。


### 4.2 我该怎么做
整理成型的数据集应该形如下面的格式：
用户id, 动漫id, 打分，最近观看时间， 一系列动漫画像特征， 一系列用户画像特征

然后依据观看时间的先后顺序，把整个数据集分成训练集和测试集，形如：
user_id anime_id    score
100250  1           8
        10          7
        21          0
        35          0
        160         10
        176         8
        334         4
———————————————————————————
        929         7
        2045        9
        5674        5
黄线上面是训练集，下面是测试集，画像特征省略。我们根据画像特征并结合一定的规则，对每个用户召回一定数量的动画，然后扔到测试集上进行打分预测并排序。我们期望的是对这个100250用户，召回的动漫在经过排序后，能够有929, 2045, 5674这几个动画留在我们的最终推荐列表里(分高)

### 4.1 特别注意的点
&nbsp; &nbsp; &nbsp; &nbsp;**下面几点要特别注意！！！！**

- 需要特别关注status=4的动画，他们是dropped！！
- 我觉得最后的训练集里，**不应该出现my_status这个字段**。因为如果出现的话，测试集也要有这个字段，但是测试集是测试推荐结果的，测试集里的anime_id就是我给这个用户召回的动画id，但是并不存在说这个用户正在观看这个动画，或是已经看完这个动画了等状态。
- 除了status=2的基本评分了以外，像是plan to watch, watching的动画都没有打分，这些属于隐反馈数据
- 还有，有很多观看动画的数据感觉需要过滤掉。比如last_update_time=1970-01-01的。。这不科学，不应该放入训练集中。**
- 时间只是用来分割训练测试集，但是不进入模型（不是一个特征）
- 因为用户信息表user_clean里的统计数据是全表的，比如user_completed，但是我们训练的时候，这个用户还没有看到过这么多动漫！！**因此像user_completed, user_dropped等特征需要重新计算。**
- favouritelist没有摘录，因此无法重算，只能删掉。。
- 有一个字段是my_watched_episodes，感觉可以用它除以这个动画的总集数来作为一个新特征

### 4.2 训练集的Y是什么
&nbsp; &nbsp; &nbsp; &nbsp;关于训练集的Y，我的想法是这样的：下午查了资料，在项亮的《推荐系统实践》这本书中有讲到：“预测用户是否会看一部电影，应该比预测用户看了电影后会给它什么评分更加重要。TopN推荐更符合实际需求。”我倾向于把训练集的因变量y设为0-1变量，模型就是一个二分类模型。**训练集中的y = 1表示我告诉模型用户会想看这本动画, y = 0表示我告诉模型用户不会想看这本动画。y由score和status综合决定，训练集中的score以及status都是为了让我们能够更准确的在未来为用户来推荐他们会看的动画**。

&nbsp; &nbsp; &nbsp; &nbsp;因此，如果训练集里有一条记录是status = 2 & score = 4，应该标记为y=0而不是y=1：因为**我们想要告诉模型的是：这个用户不会再想看这类动画的**。同样的，如果训练集里有一条记录是status = 4 ，也应该标记为y=0：因为用户半途弃了这本动画，我们以后可以不再推荐类似的了。倘若我们给这个dropped的动画标记为y=1，那么可能为这个用户召回的某一本类似的动画，会被模型预测出一个较高的概率，然而从常理上来看，这不符合。。

&nbsp; &nbsp; &nbsp; &nbsp;上面谈的都是训练集，**而对于测试集来说，y的选择应该会有所不同。测试集里的y的含义应该是：用户看了这部动画吗？同样是completed的状态，在训练集里如果得分很低的话，应该标记y=0，但是在测试集里我们应当设y=1才对(此时不考虑得分)。**换句话说，我在测试集里就只关心用户看了这部动画没，有一个字段是my_watch_episodes，表示用户看了这部动画的集数，只要这个集数不是0，就令测试集的y=1，只有集数是0的时候才令y=0。

&nbsp; &nbsp; &nbsp; &nbsp;总而言之，训练集的0-1映射关系是可以变的（可以多次试验，找比较好的关系，不过这只是经验上的处理），但是要固定测试集上的0-1标准不变。（即评估标准不变，只关心用户他看没看我给他推荐的动画）


对于训练集：

- watching, completed, on hold的状态，如果打分大于7分令y=1，否则y=0
- dropped的状态，y=0
- plan to watch的状态，因为这部分样本占比约25%，而且都没有打分消息，我考虑把他们从训练集里删除，但是可以统计信息，整合到用户相关特征里去
- **其余score = 0的部分，我暂时的想法是删了，然后整合到用户相关特征里去（或者干脆直接删了。。）建平老师的建议是可以先删了，做一次模型效果看，然后考虑用最近的样本的平均得分来预测这个缺失的打分。(如果这么做的话，在预测完打分后，filterd_anime_list也会发生变化，所以相似度矩阵W需要重新计算了, 因为可能有些动漫被喜欢的次数变多了(得分是0，但是预测出的打分>=8之类的))除了knn之类的，也可以用比如说，这个用户看的相似的动漫的平均分来作为这个动漫的平均分，这个我觉得也是可行的。**


对于测试集：

- 就看my_watch_episodes这个字段，非零的话就y=1，零的话就y=0

最后训练的时候，得分和status都不进模型，只有y进。**对于预测，因为每个用户可能在t时刻后观看的动画数都是不一样的，所以对于测试集里的动画来说，和t越近的时候看的动画可以赋予一个更高的权重。最后的Recall和Precision可以做加权修正。**

**在算物品相似度矩阵的时候，别忘了把训练集的y补上，并且把status = 6的样本删掉！！**


**又遇到一个问题，假如推荐给用户的动画，在那个时间点还未上映怎么办？**


&nbsp; &nbsp; &nbsp; &nbsp;不能单纯按时间划分，还得考虑新番的问题，比如我按2017-07-21划分训练/测试，但是在2017年7月的某一部新番，可能在前面看的人很少，但是后面看的人会很多。对于item-CF来说，应该限定物品是在训练集时间段内已上映的动画，召回的也是已经上映了的动画。对于那些新番，应该用别的方法召回。比如新番和现有的relation等。所以，**动漫相似矩阵W涉及的动画只有在T时刻前开始了的动画！itemCF给用户推荐的是老番。**评价item-CF的召回效果时，只比较T时刻后这个用户看的“老番”；而对于这个用户看的新番，应该是对比别的召回方法。

&nbsp; &nbsp; &nbsp; &nbsp;可能有这样的情况，我以2016-06-30为界限划分训练测试集，半年番Re0是16年4月开始上映，到16年9月才完结。因为数据集里的p_date列表示的是用户的AnimeList最后更新的时间，以追番为例通常会在完结的那天更新。**所以在测试集里会出现这个用户看了Re0，但是实际上他在训练集期间就已经在看了，只是训练集里没有相关记录。**那么，如果我们最终为他推荐的结果里有Re0这本动漫，应当是一个好的结果，这说明我们在不知道他已经看了Re0的情况下，作出了他会想看Re0的判断。同时，**这部在4月上映的动画应该被加入到W矩阵的计算中。如果我们能通过itemCF召回Re0，那说明在7月前有很多看过这个用户喜欢的一些其他动画，的其他用户，他们也都在7月前看了Re0，并且打了高分。**



对于这种情况，我们应该选择的是在2016-06-30之前已经开始了的那些动画作为计算W的候选集，如果有挺多的人在训练集期间

**动画和电影的区别在于动画有一个连续上映的时间区间，而电影是一天就结束了，这也是这个数据集和movielens不一样的，是一个值得再加探讨的地方。动画信息表中的related字段也可以作为召回的一个方式！**时间字段不进入最后的模型！！

### 4.3 不同的召回方法

- item-CF召回
- related召回：
'Adaptation'：我感觉这个应该是改编。或者是原作漫画。比如死神bleach的漫画和动画之间就互为Adaptation.
'Sequel'：续集。这个和Prequel是一一对应的。比如A的Prequel是B，那么B的Sequel就是A。**动漫A的ova通常是作为A的Sequel相关。**
'Prequel'：前传
'Other', 
'Parent story'：父篇,这个和Side story应该是一一对应的。比如A的Side Story是B，那么B的Parent story就是A
'Side story'：番外
'Alternative version', 
'Summary'：有点类似总集？
'Spin-off'：根据原著改编而成的
'Full story', 
'Alternative setting', 
'Character'
- 冷启动召回，分为用户冷启动和动漫冷启动，即：给新用户推荐，还有给用户推荐新番。
    1. 用户冷启动：根据用户的人口统计学信息，年龄分类、性别分类
    2. 动漫冷启动：新番和老番的相似度查询。。。

&nbsp; &nbsp; &nbsp; &nbsp; 召回可以用多种算法，不同算法的召回数目可以根据他们的表现来决定，表现好的算法可以分配一个大一点的权重。还要满足排序阶段算法的性能。
在各种召回算法完成后，需要对结果进行合并，并去重，同时标记上每一个结果是来源于哪个/哪些召回算法的。



user_clean(采样后): 5436人
train_non_zero: 5258人(1236非零+4)
train_zero: 4545人123的0分）
train_plan_to_watch: 4453人（6的0分）
train: 5315人（上面三个train的并集）
user_stats：5436人
---
test: 2535人
test_recall(item_CF): 2367人（老用户共2415人中，有2367人是能通过item_CF召回的，其余是[]）
test_related_recall(related召回): 2364人（老用户共2415人中，有2364人是能通过item_CF召回的，其余是[]）
test里的新用户（没在上述三个train的任意一个中出现的user）：120人




关于用户冷启动召回，一开始是性别和年龄分开召回的，这样最少的用户是被召回到12部~19部不等
如果换成性别+年龄的话，会多出很多用户的召回结果是空。这是因为有些年龄分段的人很少，比如Teenager和Middle Aged
这样这部分的ranking动画可能全都被这个用户看过了，那就不推荐了（比如一个16岁男性，满足16岁男性条件的召回一共就14部。。）
还有就是原本的
r = a.query('cnt>=100').reset_index()    # 选出在train_non_zero中记录数超过100的动漫, 防止太过小众 
这句代码会删掉好多。比如原本女性青少年人数就不多。。

但是我又经过对比：
        gender+Age(30%)      gender, age分开后合并   gender+Age(20%) 
count    2535.000000    2535.000000
mean       17.274162    15.043787
std         4.772755    2.192595
min         0.000000    10.000000
25%        16.000000    13.000000
50%        20.000000    15.000000
75%        20.000000    17.000000
max        20.000000    20.000000

gender+Age: 有13%的用户小于10个,但是只有23%的用户小于15个
分开召回后合并：下限保证了10个，但是有61%的用户小于15个。。






### 4.1 数据集的压缩
参考博客：[使用pandas优化Spark内存消耗（节省90%](https://blog.csdn.net/fengyuruhui123/article/details/78185321)

&nbsp; &nbsp; &nbsp; &nbsp;先读入了300w行数据，占用内存约1GB。下面逐步优化内存占用：

- 因为所有的int型列都是正数，因此可以用uint来减少占用。这一步结束后占用内存942MB
- my_tags列没什么用，删了。这一步结束后占用内存835MB
- my_start_date和my_finish_date列没用，删了。这一步结束后占用内存大幅下降，变成451MB
- 把my_last_updated列从原本的字符串格式，拆分成三列分别为年、月、日的整数形式。这一步结束后占用内存302MB
- 把上一步拆分结果的那三列int64向下类型转换。这一步结束后占用内存245MB
- 此时的数据集还有一列username是object类型的。把他join上用户信息表的user_id，并向下类型转换。这一步结束后占用内存降为91.6MB！
- 